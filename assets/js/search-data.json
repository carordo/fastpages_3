{
  
    
        "post0": {
            "title": "Pandemic Flu Spread Using “Green” Simulation Method for Small Sample of Elementary Students",
            "content": "replications=100 kids=21 days=30 p=0.02 #initializes the data frame of replications summary_df_replications = pd.DataFrame(data= {&#39;day&#39;:[], &#39;infected&#39;:[], &#39;susceptible&#39;:[],&#39;recovered&#39;:[], &#39;probability&#39;:[], &#39;count_prn&#39;:[] }) #initializes the list of last recovered which I will be saving in a data frame for every iteration summary_last_recovered=summary_df_replications mean_per_day =pd.DataFrame(data= {&#39;day&#39;:[], &#39;infected&#39;:[], &#39;susceptible&#39;:[],&#39;recovered&#39;:[], &#39;probability&#39;:[], &#39;count_prn&#39;:[] }) #runs every iteration for i in range (0, replications): metrics_result, info_last_recovered = pandemic (kids, days+1, p ) #n number of students, k number of days and p probability #in this case 21 students with a lenght of 365 days and probability of 0.02 #creates a single data frame for all replications summary_df_replications=pd.concat([summary_df_replications, pd.DataFrame(data=metrics_result)]) #creates a single data frame for all replications last recovered summary_last_recovered=pd.concat([summary_last_recovered, pd.DataFrame(data=info_last_recovered)]) . All 21 removed: in day 12 . def getDayNoInfection(df, infected=&#39;infected&#39;): counter = 0 index = 0 #print(df.head()) for index,d in df.iterrows(): if d[infected] == 0: counter = counter + 1 if counter == 0: index = d[&#39;day&#39;] if counter &gt;= 3: break return index-1 def getDaysOfNoInfectionsMean(df): days_change = [] for i in range(replications): day = getDayNoInfection(df[i*60: i*60 + 60]) days_change.append(day) out= sum(days_change)/len(days_change) #print(out) return (out, days_change) last_infected= getDaysOfNoInfectionsMean(summary_df_replications) #print(counter) . #show the table of summary_df_replications #print(summary_df_replications[0:days]) print (&quot;Table of Replications&quot;) display(summary_df_replications) #testing to see the tail of the entire dataframe #print (summary_df_replications.tail()) #test to see data from the daya of last recovered print (&quot;Last Day of The Iteration per Replication&quot;) display(summary_last_recovered) . Table of Replications . day infected susceptible recovered probability count_prn . 0 1.0 | 2.0 | 19.0 | 0.0 | 0.03960 | 20.0 | . 1 2.0 | 3.0 | 18.0 | 0.0 | 0.05881 | 39.0 | . 2 3.0 | 5.0 | 16.0 | 0.0 | 0.09608 | 57.0 | . 3 4.0 | 4.0 | 15.0 | 2.0 | 0.07763 | 73.0 | . 4 5.0 | 4.0 | 14.0 | 3.0 | 0.07763 | 88.0 | . ... ... | ... | ... | ... | ... | ... | . 25 26.0 | 0.0 | 5.0 | 16.0 | 0.00000 | 234.0 | . 26 27.0 | 0.0 | 5.0 | 16.0 | 0.00000 | 239.0 | . 27 28.0 | 0.0 | 5.0 | 16.0 | 0.00000 | 244.0 | . 28 29.0 | 0.0 | 5.0 | 16.0 | 0.00000 | 249.0 | . 29 30.0 | 0.0 | 5.0 | 16.0 | 0.00000 | 254.0 | . 2982 rows × 6 columns . Last Day of The Iteration per Replication . day infected susceptible recovered probability count_prn . 0 30.0 | 0.0 | 9.0 | 12.0 | 0.0 | 328.0 | . 0 30.0 | 0.0 | 20.0 | 1.0 | 0.0 | 600.0 | . 0 30.0 | 0.0 | 20.0 | 1.0 | 0.0 | 600.0 | . 0 30.0 | 0.0 | 3.0 | 18.0 | 0.0 | 254.0 | . 0 30.0 | 0.0 | 10.0 | 11.0 | 0.0 | 339.0 | . ... ... | ... | ... | ... | ... | ... | . 0 30.0 | 0.0 | 19.0 | 2.0 | 0.0 | 572.0 | . 0 30.0 | 0.0 | 7.0 | 14.0 | 0.0 | 276.0 | . 0 30.0 | 0.0 | 8.0 | 13.0 | 0.0 | 282.0 | . 0 30.0 | 0.0 | 20.0 | 1.0 | 0.0 | 600.0 | . 0 30.0 | 0.0 | 5.0 | 16.0 | 0.0 | 254.0 | . 100 rows × 6 columns . summary_last_recovered.mean() . day 29.82 infected 0.00 susceptible 13.44 recovered 7.56 probability 0.00 count_prn 440.23 dtype: float64 . import matplotlib.pyplot as plt import seaborn as sns fig = plt.figure(figsize=(12, 10)) ########## Plotting the first iteration ################# ax = [fig.add_subplot(311, axisbelow=True)] pal = sns.color_palette(&quot;tab10&quot;) max_infected=max(summary_df_replications[&quot;infected&quot;][0:days]) #top plot ax[0].stackplot(summary_df_replications[&quot;day&quot;][0:days], summary_df_replications[&quot;infected&quot;][0:days], summary_df_replications[&quot;susceptible&quot;][0:days], summary_df_replications[&quot;recovered&quot;][0:days], colors=pal, alpha=0.7) ax[0].set_title(f&#39;Susceptible, Infected,and Recoveredwith with {kids} kids, in {days} days, p={p}. First iteration&#39;) ax[0].set_xlabel(&#39;Days&#39;) ax[0].legend([ &#39;Infected&#39;, &#39;Susceptible&#39;, &#39;Recovered&#39;], loc=&#39;best&#39;) ax[0].set_xlim(1, days-1) ax[0].set_ylim(0, kids) #this plots a line with the max infected ax[0].annotate(&quot;Max infected(%.2f)&quot;%(max_infected), (0, max_infected),(0+3, max_infected+3), #(max_infected, max_infected), arrowprops=dict(arrowstyle=&#39;-&gt;&#39;)) ax[0].plot(np.array([0, days-1]), [max_infected, max_infected], lw=3, label=&#39;Max Infected&#39;) . [&lt;matplotlib.lines.Line2D at 0x235e33f5b08&gt;] . summary_df_replications_Table= summary_df_replications.rename(columns={&quot;day&quot;: &quot;Day&quot;,&quot;infected&quot;:&quot;Infected&quot;, &quot;susceptible&quot;:&quot;Susceptible&quot;, &quot;recovered&quot;:&quot;Removed&quot;,&quot;probability&quot;: &quot;Probability&quot;, &quot;count_prn&quot;: &quot;Cumulative PRNs&quot; } ) #summary_df_replications_Table.iloc[0:int(last_infected)] #type summary_df_replications_Table = summary_df_replications_Table.astype({&quot;Day&quot;: int, &quot;Infected&quot;: int}) . #calculates the mean per replications #not correcto start mean_replications = pd.DataFrame(summary_last_recovered.mean(axis=0)).T mean_replications # not correcto end #mean of first iteration #print(summary_df_replications[&quot;infected&quot;][0:days].mean()) #mean of the day 1 #print(f&#39;Mean of day 1 :{summary_df_replications[&quot;infected&quot;][0].mean()}&#39;) #mean of all days 1 mean_of_days_infected=[] mean_of_days_susceptible=[] mean_of_days_removed=[] #calculating the variance per day var_of_days_infected=[] var_of_days_susceptible=[] var_of_days_removed=[] #creating a table only for the infected values #if the mean is taking for all of the days including the 0 the mean will also include zero values #set the range of the days x=range(1,days) for i in range(0,days-1): mean_of_days_infected.append(summary_df_replications[&quot;infected&quot;][i].mean()) mean_of_days_susceptible.append(summary_df_replications[&quot;susceptible&quot;][i].mean()) mean_of_days_removed.append(summary_df_replications[&quot;recovered&quot;][i].mean()) #for the variance var_of_days_infected.append(summary_df_replications[&quot;infected&quot;][i].var()) var_of_days_susceptible.append(summary_df_replications[&quot;susceptible&quot;][i].var()) var_of_days_removed.append(summary_df_replications[&quot;recovered&quot;][i].var()) #print(summary_df_replications[&quot;infected&quot;][i].mean()) #print(f&#39;mean of each day {mean_of_days_infected}&#39;) dataframe_means= pd.DataFrame(data={&#39;Day&#39;:x, &#39;mean_per_day_infected&#39;:mean_of_days_infected, &#39;mean_of_days_susceptible&#39;:mean_of_days_susceptible, &#39;mean_of_days_removed&#39;:mean_of_days_removed}) #creates a dataframeof the variances dataframe_variance=pd.DataFrame(data={&#39;Day&#39;:x, &#39;Variance per day Infected&#39;:var_of_days_infected, &#39;Variance per day Susceptible&#39;:var_of_days_susceptible, &#39;Variance per day Recovered&#39;:var_of_days_removed} ) . last_infected_mean= getDayNoInfection(dataframe_means,&#39;mean_per_day_infected&#39;) print(f&#39;Day that no more kids gets infected {last_infected_mean}th day&#39;) dataframe_means print() mean_days, array_days= getDaysOfNoInfectionsMean(summary_df_replications) End_total_infection = summary_df_replications[summary_df_replications[&quot;infected&quot;]&lt;1] #End_total_infection[] #getDaysOfNoInfectionsMean(summary_df_replications) . Day that no more kids gets infected 23th day . #this plots the info in a stack fig = plt.figure(figsize=(12, 10)) ax = [fig.add_subplot(311, axisbelow=True), fig.add_subplot(312, axisbelow=True)] plt.xticks(np.arange(min(x), max(x)+1, 1.0)) max_infected_means=max(dataframe_means[&quot;mean_per_day_infected&quot;][0:days]) print(max_infected_means) ax[0].stackplot(dataframe_means[&quot;Day&quot;][0:days], dataframe_means[&quot;mean_per_day_infected&quot;][0:days], dataframe_means[&quot;mean_of_days_susceptible&quot;][0:days], dataframe_means[&quot;mean_of_days_removed&quot;][0:days], colors=pal, alpha=0.7) ax[0].set_title(f&#39;Expected Value of Susceptible, Infected,and Recoveredwith with {kids} kids, in {days} days, p={p}, replications= {replications}&#39;) ax[0].set_xlabel(&#39;Days&#39;) ax[0].set_ylabel(&#39;Expected Value per Status&#39;) ax[0].legend([ &#39;Infected&#39;, &#39;Susceptible&#39;, &#39;Recovered&#39;], loc=&#39;center&#39;) ax[0].set_xlim(1, days-2) ax[0].set_ylim(0, kids) #this plots a line with the max infected ax[0].annotate(&quot;Max infected(%.2f)&quot;%(max_infected_means), (0, max_infected_means),(0+3, max_infected_means+3), #(max_infected, max_infected), arrowprops=dict(arrowstyle=&#39;-&gt;&#39;)) ax[0].plot(np.array([0, days-1]), [max_infected_means, max_infected_means], lw=3, label=&#39;Max Infected Means&#39;) #this plots a line with the last day infected ax[0].annotate(&quot;End of Infections(%.2f)&quot;%(last_infected_mean), (last_infected_mean, 0),(last_infected_mean-6, 0+5), #(max_infected, max_infected), arrowprops=dict(arrowstyle=&#39;-&gt;&#39;)) ax[0].annotate(&quot;End of Infections(%.2f)&quot;%(last_infected_mean), (last_infected_mean, 0),(last_infected_mean-6, 0+5), #(max_infected, max_infected), arrowprops=dict(arrowstyle=&#39;-&gt;&#39;)) ax[0].plot(np.array([last_infected_mean,last_infected_mean]), [0, kids], lw=3, label=&#39;Last Infected Means&#39;) ############################################################################################# #This plot is for the infected on the sencond part ax[1].set_xlim(1, days-2) ax[1].set_ylim(0, max_infected_means*3) ax[1].stackplot(x, dataframe_means[&quot;mean_per_day_infected&quot;][0:days-1], dataframe_variance[&quot;Variance per day Infected&quot;][0:days-1], colors=pal, alpha=0.7) ax[1].legend([ &#39;Expected Value of Infected&#39;, &#39;Variance of Infected&#39;], loc=&#39;center&#39;) #this plots a vertical line of end of infection in plot 2 ax[1].annotate(&quot;End of Infections(%.2f)&quot;%(last_infected_mean), (last_infected_mean, 0),(last_infected_mean-6, 0+1), #(max_infected, max_infected), arrowprops=dict(arrowstyle=&#39;-&gt;&#39;)) ax[1].plot(np.array([last_infected_mean,last_infected_mean]), [0, kids], lw=3, label=&#39;Last Infected Means&#39;) #sets x title ax[1].set_xlabel(&#39;Days&#39;) ax[1].set_ylabel(&#39;Expected Value and Variance of Infected&#39;) . 2.84 . Text(0, 0.5, &#39;Expected Value and Variance of Infected&#39;) . from scipy import stats #[dataframe_means[&quot;mean_per_day_infected&quot;], #dataframe_variance[&quot;Variance per day Infected&quot;]] #testing how to run the chi squuare Xnot=chisquare([179, 208, 222, 199, 192]) #Cacluclates the Chi square passing 1- alph, degrees of freedom Xalpha = stats.chi2.ppf(q=0.95, df=4) print(Xnot,Xalpha) # for the project Xnot=chisquare(summary_df_replications[&quot;infected&quot;]) #Cacluclates the Chi square passing 1- alph, degrees of freedom k_observation=len(summary_df_replications[&quot;infected&quot;]) print(k_observation) Xalpha = stats.chi2.ppf(q=0.95, df=k_observation-1) print(Xnot,Xalpha) phat=.476 x=2 70*(1-phat)**(x-1)*phat (1-phat)**(x-1)*phat . NameError Traceback (most recent call last) &lt;ipython-input-13-c6ac1d942afc&gt; in &lt;module&gt; 5 6 #testing how to run the chi squuare -&gt; 7 Xnot=chisquare([179, 208, 222, 199, 192]) 8 #Cacluclates the Chi square passing 1- alph, degrees of freedom 9 Xalpha = stats.chi2.ppf(q=0.95, df=4) NameError: name &#39;chisquare&#39; is not defined . summary_last_recovered.head(5) . print(summary_last_recovered) results_replications_mean =pd.DataFrame(summary_last_recovered.mean()).T results_replications_mean_SIR= results_replications_mean.rename(columns={&quot;day&quot;: &quot;Day&quot;, &quot;infected&quot;:&quot;Total Expected Infected&quot;, &quot;susceptible&quot;:&quot;Total Expected Susceptible&quot;, &quot;recovered&quot;:&quot;Total Expected Removed&quot;, &quot;probability&quot;: &quot;Probability&quot;, &quot;count_prn&quot;: &quot;Cumulative PRNs&quot; } ) results_replications_mean_SIR[&quot;Total Expected Infected&quot;]=results_replications_mean_SIR[&quot;Total Expected Removed&quot;] results_replications_mean_SIR[&quot;Variance Infected&quot;]=0 #comparing the value if rounded display(round(results_replications_mean_SIR)) #not rounded display(results_replications_mean_SIR) display(summary_last_recovered.var()) . import statistics sample=summary_last_recovered[&quot;recovered&quot;] print(len(sample)) Zrbar= statistics.mean(sample) print(Zrbar) Sz_variance=statistics.variance(sample, xbar=Zrbar) print(Sz_variance) #1-stats.t.cdf(0.95,df=1) #enter the percentage to calculate the left side 90% equal to 10% in the regular table #np.sqrt(4) CILow=Zrbar - stats.t.ppf(0.975, df=len(sample)-1)*np.sqrt(Sz_variance/len(sample)) CIHigh =Zrbar + stats.t.ppf(0.975, df=len(sample)-1)*np.sqrt(Sz_variance/len(sample)) print(CILow,CIHigh) . summary_dataframe_means_Table= dataframe_means.rename(columns={&quot;day&quot;: &quot;Day&quot;,&quot;mean_per_day_infected&quot;:&quot;Expected Value of Infected &quot;, &quot;mean_of_days_susceptible&quot;:&quot;Excpected Value of Susceptibles&quot;, &quot;mean_of_days_removed&quot;:&quot;Expected Value of Removed&quot;} ) dataframe_means summary_dataframe_means_Table . summary_dataframe_means_Table_SIR=summary_dataframe_means_Table del summary_dataframe_means_Table_SIR[&quot;Day&quot;] summary_dataframe_means_Table.hist(figsize = (12,10)) #(summary_dataframe_means_Table[[&quot;Day&quot;, &quot;Expected Value of Infected&quot;]]).hist(column=&#39;Expected Value of Infected&#39;, bins=days,figsize=(8,4), grid=True,rwidth=0.9) . #Same as the mean olf how long the pandemic last print(f&#39;Day that no other kid gets infected = {summary_df_replications[&quot;infected&quot;].lt(1).argmax()}th day&#39;) #summary_df_replications[summary_df_replications[&quot;infected&quot;][:]&gt;0].iloc[0:20].mean() #summary_df_replications_greater_zero[&quot;infected&quot;][1].mean() #summary_df_replications.iloc[16:30] . # display(dataframe_means[dataframe_means[&quot;mean_per_day_infected&quot;][:]&gt;0]) # print (&quot;Table of Means of the Means For all Iteration&quot;) # display(dataframe_means[dataframe_means[&quot;mean_per_day_infected&quot;][:]&gt;0].mean()) . #Number of infected on day 0 for each replcation Infected_Day_1 = summary_df_replications[&quot;infected&quot;][0].iloc[0:1000] #print(Infected_Day_1) Infected_Day_1.hist( figsize=(10,4),grid=True).set_xlabel(&#39;Number of Infected on Day 1&#39;) Infected_Day_1.hist( ).set_ylabel(&#39;Frequency&#39;) . Ei=summary_df_replications[&quot;infected&quot;][0].mean() Oi=summary_df_replications[&quot;infected&quot;][0].iloc[0:1000].value_counts() print(f&#39;Ei = {Ei}&#39;) print(&#39;Observations&#39;) print(Oi) #this is incorrect Xnot=chisquare(summary_df_replications[&quot;infected&quot;][0]) #this is correct Xnot2=chisquare(Oi) #Cacluclates the Chi square passing 1- alph, degrees of freedom Xalpha = stats.chi2.ppf(q=0.95, df=len(Oi)-1-1) #print(Xnot, Xalpha) print(&#39;Xnot with stats package&#39;) print(Xnot2 ) print(&#39;X alpha&#39;) print(Xalpha) print(len(summary_df_replications[&quot;infected&quot;][0])) . Oi=summary_df_replications[&quot;infected&quot;][0].value_counts() #testing first 100 Xnot_list=[] Xbar_list=[] Xalpha_list=[] degrees=[] nlist=[] Geometric_per_replication=[] #30 days ends the replication window=60 for rep in range(1,int(990/window)-1): Oi=summary_df_replications[&quot;infected&quot;][0].iloc[(rep-1)*window:window*rep].value_counts() OiList=np.array(Oi) print(OiList) index=list(range(1,len(OiList)+1)) #[1,2,3,4,5] print(index) n=sum(OiList) print(OiList*index) sumXi=sum(OiList*index) #testing with out muliplying it for the index equal to X #sumXi=sum(OiList) Xbar=sumXi/n phat=1/Xbar print(f&#39;Phat = {phat} Xbar = {Xbar}&#39;) PGeometric=[] #phat=.476 for x in range(1,len(index)): PGeometric.append(((1-phat)**(x-1))*phat) PGeometric.append(1-sum(PGeometric)) PGeometric #n=70 nx=np.ones(len(index))*n print(nx) Ex= PGeometric*nx print(f&#39;Ex = {sum(Ex)}&#39;) #OiList=[34,18,2,9,7] Ex_OiList= Ex-OiList Xnot= sum(Ex_OiList**2/Ex) Xalpha = stats.chi2.ppf(q=0.95, df=len(Oi)-1-1) Xnot_list.append(Xnot) Xbar_list.append(Xbar) Xalpha_list.append(Xalpha) nlist.append(n) degrees.append(len(Oi)-1-1) Geometric_per_replication.append([PGeometric, Ex, Oi]) print(f&#39;Xnot = {Xnot}&#39;) #Xalpha() print(sum(PGeometric)) pd.DataFrame(data={&#39;P(X=x)&#39;:PGeometric, &#39;Ex&#39;:Ex, &#39;Ox&#39;:Oi}) Xalpha = stats.chi2.ppf(q=0.95, df=len(Oi)-1-1) print(f&#39;Xalpha = {Xalpha}&#39;) pd.DataFrame(data={&#39;P(X=x)&#39;:PGeometric, &#39;Ex&#39;:Ex, &#39;Ox&#39;:Oi}) . Geometric_per_replication . pd.DataFrame(Xnot_list).hist( ) pd.DataFrame(Xbar_list).hist( ) pd.DataFrame(Xbar_list).mean() #print(Xbar_list) #print(&#39;xxxx&#39;) #print(Xnot_list) Goodness = pd.DataFrame(data={&#39;Xnots&#39;:Xnot_list, &#39;Exs&#39;:Xbar_list, &#39;Xalphas&#39;:Xalpha_list, &#39;n&#39;:nlist, &#39;Degrees of Freedom&#39;:degrees}) Goodness[&quot;Xnot&lt;Xalpha&quot;]=Goodness[&#39;Xnots&#39;]&lt;Goodness[&#39;Xalphas&#39;] Goodness . Oi=summary_df_replications[&quot;infected&quot;][0].iloc[0:500].value_counts() #testing first 100 #Oi=summary_df_replications[&quot;infected&quot;][0].head(200).value_counts() OiList=np.array(Oi) print(OiList) index=list(range(1,len(OiList)+1)) #[1,2,3,4,5] print(index) n=sum(OiList) print(OiList*index) sumXi=sum(OiList*index) #testing with out muliplying it for the index equal to X #sumXi=sum(OiList) Xbar=sumXi/n phat=1/Xbar print(f&#39;Phat = {phat} Xbar = {Xbar}&#39;) PGeometric=[] #phat=.476 for x in range(1,len(index)): PGeometric.append(((1-phat)**(x-1))*phat) PGeometric.append(1-sum(PGeometric)) PGeometric #n=70 nx=np.ones(len(index))*n print(nx) Ex= PGeometric*nx print(f&#39;Ex = {Ex}&#39;) print(f&#39;Ox = {OiList}&#39;) #OiList=[34,18,2,9,7] Ex_OiList= Ex-OiList #print(Ex_OiList) print(f&#39;Ex - Ox = {Ex_OiList}&#39;) print(f&#39;[Ex - Ox]^2 = {Ex_OiList**2}&#39;) print(f&#39;[Ex - Ox]^2/Ex = {(Ex_OiList**2)/Ex}&#39;) print(f&#39; Sum [Ex - Ox]^2/Ex = {sum((Ex_OiList**2)/Ex)}&#39;) Xnot= sum(Ex_OiList**2/Ex) print(f&#39;Xnot = {Xnot}&#39;) #Xalpha() print(sum(PGeometric)) pd.DataFrame(data={&#39;P(X=x)&#39;:PGeometric, &#39;Ex&#39;:Ex, &#39;Ox&#39;:Oi}) Xalpha = stats.chi2.ppf(q=0.95, df=len(Oi)-1-1) print(f&#39;Xalpha = {Xalpha}&#39;) Table=pd.DataFrame(data={&#39;P(X=x)&#39;:PGeometric, &#39;Ex&#39;:Ex, &#39;Ox&#39;:Oi}) Table_add=Table.iloc[3]+Table.iloc[4] #adding tables so the last index includes 4 and 5 Adding_Tables=pd.concat([Table.head(3), pd.DataFrame(Table_add).T]) Ex_OiList=Adding_Tables[&quot;Ex&quot;]-Adding_Tables[&quot;Ox&quot;] print(Ex_OiList) Xnot= sum(Ex_OiList**2/Adding_Tables[&quot;Ex&quot;]) Xalpha = stats.chi2.ppf(q=0.95, df=len(Adding_Tables)-1-1) print(f&#39;Xnot = {Xnot}&#39;) print(f&#39;Xalpha = {Xalpha}&#39;) . sum(Ex)==sum(OiList) stats.chi2.ppf(q=0.95, df=2) len(Adding_Tables) . summary_df_replications[&quot;infected&quot;][0].iloc[30:60] . import numpy as np a=[] Xbar=Ei k=4 p=1/k #for exponential for i in range(1,k): a.append(round(Xbar*(-1*np.log(1-i/k) ),0)) print(a) #Infected_Day_1[&quot;groups&quot;]= Infected_Day_2=pd.DataFrame() Infected_Day_2[&quot;infected&quot;] = summary_df_replications[&quot;infected&quot;][0] print(Infected_Day_2.head()) Infected_Day_2[&quot;group&quot;]=pd.cut(summary_df_replications[&quot;infected&quot;][0],bins = a) Oi3=[Infected_Day_2[&quot;group&quot;].value_counts(),len(Infected_Day_2)-661-272] Oi3=[661,272,67] Oi3 Xnot3=chisquare(Oi3) Xnot3 . sample_infected = random.sample(list(Infected_Day_1), 200) k=3 Ei2=len(sample_infected)/k print(Ei2) Oi=pd.DataFrame(sample_infected) Oi=Oi[0].value_counts() print(Oi) Oi_lenEi=Oi-Ei2 print(Oi_lenEi**2/Ei2) sum(Oi_lenEi**2/Ei2) sum(Oi) . sum((Oi-len(Infected_Day_1)/k)**2/len(Infected_Day_1)/k) Ei2=len(Infected_Day_1)/k Oi_lenEi=Oi-Ei2 Oi_lenEi sum(Oi_lenEi**2/Ei2) . print( f&#39;Number of kids that are infected after {replications} replcations = {summary_df_replications[&quot;infected&quot;][0].mean()} on Day 1&#39;) . print( f&#39;Number of kids that are infected after {replications} replcations = {summary_df_replications[&quot;infected&quot;][1].mean()} on Day 2&#39;) . #Lenght_Uniform=len(summary_df_replications[&quot;infected&quot;][0]) X=summary_df_replications[&quot;infected&quot;][0] #Utest=np.random.uniform(0,1,Lenght_Uniform) #Exp_lambda=-1*(1/X)*np.log(Utest) print(f&#39;The mean number of students to get infected on the day 1 is :{X.mean(axis=0)}&#39;) . #summary_last_recovered[[&quot;susceptible&quot;,&quot;recovered&quot;]].hist(figsize = (10,5)) (summary_df_replications[[&quot;day&quot;, &quot;susceptible&quot;]]).hist(column=&#39;susceptible&#39;, bins=days,figsize=(8,4), grid=True,rwidth=0.9) (summary_df_replications[[&quot;day&quot;, &quot;infected&quot;]]).hist(column=&#39;infected&#39;, bins=days,figsize=(8,4), grid=True,rwidth=0.9) (summary_df_replications[[&quot;day&quot;, &quot;recovered&quot;]]).hist(column=&#39;recovered&#39;, bins=days,figsize=(8,4), grid=True,rwidth=0.9) . summary_last_recovered . summary_df_replications . #summary_df_replications.plot(&quot;day&quot;, y = [&quot;infected&quot;,&quot;susceptible&quot;, &quot;recovered&quot; ],figsize = (12,10)) #summary_df_replications.plot.hist(&quot;day&quot;, y = [&quot;infected&quot;,&quot;recovered&quot;,&quot;susceptible&quot; ],figsize = (12,10)) summary_df_replications[[&quot;infected&quot;,&quot;recovered&quot;,&quot;susceptible&quot;,&quot;probability&quot; ]].hist(figsize = (12,10)) . summary_last_recovered[[&quot;susceptible&quot;,&quot;recovered&quot;]].hist(figsize = (10,5)) . print(summary_df_replications.T) . summary_df_replications.hist(figsize = (16,18)) .",
            "url": "https://carordo.github.io/fastpages_3/2022/01/04/Pandemic-simulation-covid.html",
            "relUrl": "/2022/01/04/Pandemic-simulation-covid.html",
            "date": " • Jan 4, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Calculating The Cost Of Overbooking Airline Tickets Using Analytics",
            "content": "This article was originally posted on Linkedin here prior to the pandemic Using Python to calculate the cost of overbooking an airline ticket. . The code can be found in GitHub here. . I have been curious to use data analytics in aviation operations. I found that one of the models that airlines use is the binomial function to determine what is the optimum revenue the airline, after calculating the probability of the number of passengers that will show up when overbooking a specific route. The probability is modeled with binomial function assuming that each show or no show sample is independent of each other. This probability is affected by many possible factors like delayed flights, traffic jams, canceling a flight due to personal reasons, etc. . Binomial function This article was inspired by Cory Simon ’s article on “ By How Many Flights an Airline Should Overbook”. In his analysis, he uses a normal approximation of a binomial distribution. He allocates fixed parameters such as a number of seats per aircraft, the probability of a passenger and expands to a range of additional tickets beyond capacity sold the price per ticket and the price of the voucher. The voucher in his example is defined as the cost the airline incurs to pay passengers for an overbooked ticket. . I decided to expand a little more and create a function that could allow passing the value of the ticket, the voucher cost, the number of seats, the probability rate of a passenger showing up and the number of additional seats. I used Python’s numpy cumulative distributive function to calculate the probability of passengers to show to a flight beyond capacity (Total Seats Available in the aircraft + total additional overbooking tickets). The function also calculates the max number of possible seats available that could be overbooked. This is defined by p * x=Total Seats Available. If the probability is equal to 1 then all seats will be taken. By solving x, then x=Total Seats Available/p _will give the maximum seats available for that probability _p. A good explanation of the calculation of the probability of overbooking can also be found here. . Let’s assume the case of  Embraer 175  flying  Miami to Cleveland with 128 seats  in the main cabin. . Embraer-175-cabin-Layout For this calculation, I am focused on the number of additional tickets beyond capacity. The following example tests a ticket with a value of $512.00 from Miami to Cleveland in American Airlines, assuming a probability rate of passengers to show at this time on this date at 90%. The maximum number of additional seats the airline could sell is equal to_ Max_Seats = 128 /.9 = 142.22 - 128 = 14.22 _rounded down will give  14  additional seats on  128  seat aircraft, with a probability of  90 % of the passengers showing up and a voucher cost for overbooking of  $200.00. . Air Fare example for Binomial Function The airline by selling additional tickets increases its revenue, but the net profit decreases if they end up paying for too many vouchers. The voucher cost could include the cost of re-scheduling passengers. In this example, it is omitted. I am trying to find the optimum amount of additional tickets the airline could sell. . Overbooking Calculation image The result of this graph shows the maximum profit per additional ticket at a fixed voucher cost, with the maximum amount of overbooking tickets (14). The maximum total profit can be reached at $66,995.94 overbooking 6 tickets of the 14. . Expected Reveneu vs tickets beyond capacity graph Table with Expected profit by exceeding overbooking The following table test different vouchers values based on the suggested overbooking tickets found on the previous table. . Table with Overbooking tickets sold and max profit The table shows that the ideal  Voucher_Cost  should be less than $200.00, overbooking 6 seats. If the voucher cost offered is higher than $600.00 the airline should not overbook any additional tickets. . This analysis is just the first to understand a model, in this case, the binomial function, when applying analytics in aviation operations. It is important to highlight that there are 4 moving variables: Ticket sale price, the voucher cost, probability of passengers to show at a specific time and date, and the number of seats per aircraft. .",
            "url": "https://carordo.github.io/fastpages_3/2020/08/15/calculating-the-cost-of-overbooking-airline/",
            "relUrl": "/2020/08/15/calculating-the-cost-of-overbooking-airline/",
            "date": " • Aug 15, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://carordo.github.io/fastpages_3/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://carordo.github.io/fastpages_3/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am an electrical engineer, data scientist, business focused, helping companies adopt a digital mindset. . To learn more about me, check my LinkedIn. . This website is powered by fastpages 1.Disclaimer2 . A blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . | Disclaimer: The information provided by me on this website (“Site”) is for general informational purposes only. All information on the Site is provided in good faith, however we make no representation or warranty of any kind, express or implied, regarding the accuracy, adequacy, validity, reliability, availability or completeness of any information on the Site.Under no circumstance shall we have any liability to you for any loss or damage of any kind incurred as a result of the use of the site or reliance on any information provided on the site. Your use of the site [and our mobile application] and your reliance on any information on the site is solely at your own risk. &#8617; . |",
          "url": "https://carordo.github.io/fastpages_3/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://carordo.github.io/fastpages_3/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}