{
  
    
        "post0": {
            "title": "Financial Analysis  Excel Basics",
            "content": "Financial Analysis – Excel Basics . Excel Basics . Change from Manual to Automatic . Sometimes the data could be in manual to avoid error in the formulas. To change it to automatic: . Go to Formulas/Calculation Options/ change to Automatic | . Use of solver . You can use solver to set a specific value depending on the on the desired outcome. . Find the present value to be 100.00 . | Change the interest rate . | Set the objective to be the cell of the present value $B$4 . | By changing variable cells to be the interest rate: $B$1 . | Solve . | Similarly using the constraints by adding the range on which the value could change. . | In this example how to get an A on the last exam . | . . The solver returns 100 for Exam 3 . . Pivot Tables . Use pivot tables to manage large amounts of data. By clicking inside the table Excel understands the limits of the data. . In this case, this data for two campanies, the pivot table shows the average per month . . To group it by quarters, highlight the months, right click/Group/Quarters . . Sensitivity Analysis . Find out how the value of the company changes based on the changes on some of the inputs. . Terminal Value calculates the value in this case from year 4 to infinitive. . . Free cash flows are calculated until year 3 then find terminal value. Add it to year 3, the calculate Present Value (PV) using NPV | . . In order to create a table that shows the variation of the required return and the grow rate, create a table where the values of each in these variables are in row column format with the value of the firm at he corner. Select the data/ Go to Data/ What-if Analysis / Data Table/ Select row input and grow rate constant/ok . . . We can see the table from changes the values on the left side is equal to full table on the right side . . How to create a button . Include the Developer tab. Right click on the ribbon select Developer. . . Insert the radio button | . . Right click/ Format control/Cell link and select a cell. . | If another radio button is created, then value of the cell could toggle between the buttons. In this example value is changing between 1 and 2. If changes, the value changes from 100 to 150 . | . . Hide the cell by changing the color of number 2 to white | . VLookup – Looks up a value vertically. . In this example we are looking for the name and returning how high the dog will jump in feet . .",
            "url": "https://www.carlosaordonez.com/2022/01/16/Financial-Analysis-Excel-Basics.html",
            "relUrl": "/2022/01/16/Financial-Analysis-Excel-Basics.html",
            "date": " • Jan 16, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Code - Pandemic Flu Spread Using “Green” Simulation Method for Small Sample of Elementary Students",
            "content": "This paper studies a pandemic flu spread case applying a “green” simulation method, using pseudo-random numbers as presented in the paper by Wilson S., Alabdulkarim A. and Goldsman D. W, “Green Simulation of Pandemic Disease Propagation” in a simulation environment build in Python. The scenario is an elementary school with twenty-one kids and the impact of infection when one infected kid enters the system. The findings and answers to the questions are presented at the end of the paper. The paper can be read here. . replications=100 kids=21 days=30 p=0.02 #initializes the data frame of replications summary_df_replications = pd.DataFrame(data= {&#39;day&#39;:[], &#39;infected&#39;:[], &#39;susceptible&#39;:[],&#39;recovered&#39;:[], &#39;probability&#39;:[], &#39;count_prn&#39;:[] }) #initializes the list of last recovered which I will be saving in a data frame for every iteration summary_last_recovered=summary_df_replications mean_per_day =pd.DataFrame(data= {&#39;day&#39;:[], &#39;infected&#39;:[], &#39;susceptible&#39;:[],&#39;recovered&#39;:[], &#39;probability&#39;:[], &#39;count_prn&#39;:[] }) #runs every iteration for i in range (0, replications): metrics_result, info_last_recovered = pandemic (kids, days+1, p ) #n number of students, k number of days and p probability #in this case 21 students with a lenght of 365 days and probability of 0.02 #creates a single data frame for all replications summary_df_replications=pd.concat([summary_df_replications, pd.DataFrame(data=metrics_result)]) #creates a single data frame for all replications last recovered summary_last_recovered=pd.concat([summary_last_recovered, pd.DataFrame(data=info_last_recovered)]) . All 21 removed: in day 12 . def getDayNoInfection(df, infected=&#39;infected&#39;): counter = 0 index = 0 #print(df.head()) for index,d in df.iterrows(): if d[infected] == 0: counter = counter + 1 if counter == 0: index = d[&#39;day&#39;] if counter &gt;= 3: break return index-1 def getDaysOfNoInfectionsMean(df): days_change = [] for i in range(replications): day = getDayNoInfection(df[i*60: i*60 + 60]) days_change.append(day) out= sum(days_change)/len(days_change) #print(out) return (out, days_change) last_infected= getDaysOfNoInfectionsMean(summary_df_replications) #print(counter) . #show the table of summary_df_replications #print(summary_df_replications[0:days]) print (&quot;Table of Replications&quot;) display(summary_df_replications) #testing to see the tail of the entire dataframe #print (summary_df_replications.tail()) #test to see data from the daya of last recovered print (&quot;Last Day of The Iteration per Replication&quot;) display(summary_last_recovered) . Table of Replications . day infected susceptible recovered probability count_prn . 0 1.0 | 2.0 | 19.0 | 0.0 | 0.03960 | 20.0 | . 1 2.0 | 3.0 | 18.0 | 0.0 | 0.05881 | 39.0 | . 2 3.0 | 5.0 | 16.0 | 0.0 | 0.09608 | 57.0 | . 3 4.0 | 4.0 | 15.0 | 2.0 | 0.07763 | 73.0 | . 4 5.0 | 4.0 | 14.0 | 3.0 | 0.07763 | 88.0 | . ... ... | ... | ... | ... | ... | ... | . 25 26.0 | 0.0 | 5.0 | 16.0 | 0.00000 | 234.0 | . 26 27.0 | 0.0 | 5.0 | 16.0 | 0.00000 | 239.0 | . 27 28.0 | 0.0 | 5.0 | 16.0 | 0.00000 | 244.0 | . 28 29.0 | 0.0 | 5.0 | 16.0 | 0.00000 | 249.0 | . 29 30.0 | 0.0 | 5.0 | 16.0 | 0.00000 | 254.0 | . 2982 rows × 6 columns . Last Day of The Iteration per Replication . day infected susceptible recovered probability count_prn . 0 30.0 | 0.0 | 9.0 | 12.0 | 0.0 | 328.0 | . 0 30.0 | 0.0 | 20.0 | 1.0 | 0.0 | 600.0 | . 0 30.0 | 0.0 | 20.0 | 1.0 | 0.0 | 600.0 | . 0 30.0 | 0.0 | 3.0 | 18.0 | 0.0 | 254.0 | . 0 30.0 | 0.0 | 10.0 | 11.0 | 0.0 | 339.0 | . ... ... | ... | ... | ... | ... | ... | . 0 30.0 | 0.0 | 19.0 | 2.0 | 0.0 | 572.0 | . 0 30.0 | 0.0 | 7.0 | 14.0 | 0.0 | 276.0 | . 0 30.0 | 0.0 | 8.0 | 13.0 | 0.0 | 282.0 | . 0 30.0 | 0.0 | 20.0 | 1.0 | 0.0 | 600.0 | . 0 30.0 | 0.0 | 5.0 | 16.0 | 0.0 | 254.0 | . 100 rows × 6 columns . summary_last_recovered.mean() . day 29.82 infected 0.00 susceptible 13.44 recovered 7.56 probability 0.00 count_prn 440.23 dtype: float64 . import matplotlib.pyplot as plt import seaborn as sns fig = plt.figure(figsize=(12, 10)) ########## Plotting the first iteration ################# ax = [fig.add_subplot(311, axisbelow=True)] pal = sns.color_palette(&quot;tab10&quot;) max_infected=max(summary_df_replications[&quot;infected&quot;][0:days]) #top plot ax[0].stackplot(summary_df_replications[&quot;day&quot;][0:days], summary_df_replications[&quot;infected&quot;][0:days], summary_df_replications[&quot;susceptible&quot;][0:days], summary_df_replications[&quot;recovered&quot;][0:days], colors=pal, alpha=0.7) ax[0].set_title(f&#39;Susceptible, Infected,and Recoveredwith with {kids} kids, in {days} days, p={p}. First iteration&#39;) ax[0].set_xlabel(&#39;Days&#39;) ax[0].legend([ &#39;Infected&#39;, &#39;Susceptible&#39;, &#39;Recovered&#39;], loc=&#39;best&#39;) ax[0].set_xlim(1, days-1) ax[0].set_ylim(0, kids) #this plots a line with the max infected ax[0].annotate(&quot;Max infected(%.2f)&quot;%(max_infected), (0, max_infected),(0+3, max_infected+3), #(max_infected, max_infected), arrowprops=dict(arrowstyle=&#39;-&gt;&#39;)) ax[0].plot(np.array([0, days-1]), [max_infected, max_infected], lw=3, label=&#39;Max Infected&#39;) . [&lt;matplotlib.lines.Line2D at 0x235e33f5b08&gt;] . summary_df_replications_Table= summary_df_replications.rename(columns={&quot;day&quot;: &quot;Day&quot;,&quot;infected&quot;:&quot;Infected&quot;, &quot;susceptible&quot;:&quot;Susceptible&quot;, &quot;recovered&quot;:&quot;Removed&quot;,&quot;probability&quot;: &quot;Probability&quot;, &quot;count_prn&quot;: &quot;Cumulative PRNs&quot; } ) #summary_df_replications_Table.iloc[0:int(last_infected)] #type summary_df_replications_Table = summary_df_replications_Table.astype({&quot;Day&quot;: int, &quot;Infected&quot;: int}) . #calculates the mean per replications #not correcto start mean_replications = pd.DataFrame(summary_last_recovered.mean(axis=0)).T mean_replications # not correcto end #mean of first iteration #print(summary_df_replications[&quot;infected&quot;][0:days].mean()) #mean of the day 1 #print(f&#39;Mean of day 1 :{summary_df_replications[&quot;infected&quot;][0].mean()}&#39;) #mean of all days 1 mean_of_days_infected=[] mean_of_days_susceptible=[] mean_of_days_removed=[] #calculating the variance per day var_of_days_infected=[] var_of_days_susceptible=[] var_of_days_removed=[] #creating a table only for the infected values #if the mean is taking for all of the days including the 0 the mean will also include zero values #set the range of the days x=range(1,days) for i in range(0,days-1): mean_of_days_infected.append(summary_df_replications[&quot;infected&quot;][i].mean()) mean_of_days_susceptible.append(summary_df_replications[&quot;susceptible&quot;][i].mean()) mean_of_days_removed.append(summary_df_replications[&quot;recovered&quot;][i].mean()) #for the variance var_of_days_infected.append(summary_df_replications[&quot;infected&quot;][i].var()) var_of_days_susceptible.append(summary_df_replications[&quot;susceptible&quot;][i].var()) var_of_days_removed.append(summary_df_replications[&quot;recovered&quot;][i].var()) #print(summary_df_replications[&quot;infected&quot;][i].mean()) #print(f&#39;mean of each day {mean_of_days_infected}&#39;) dataframe_means= pd.DataFrame(data={&#39;Day&#39;:x, &#39;mean_per_day_infected&#39;:mean_of_days_infected, &#39;mean_of_days_susceptible&#39;:mean_of_days_susceptible, &#39;mean_of_days_removed&#39;:mean_of_days_removed}) #creates a dataframeof the variances dataframe_variance=pd.DataFrame(data={&#39;Day&#39;:x, &#39;Variance per day Infected&#39;:var_of_days_infected, &#39;Variance per day Susceptible&#39;:var_of_days_susceptible, &#39;Variance per day Recovered&#39;:var_of_days_removed} ) . last_infected_mean= getDayNoInfection(dataframe_means,&#39;mean_per_day_infected&#39;) print(f&#39;Day that no more kids gets infected {last_infected_mean}th day&#39;) dataframe_means print() mean_days, array_days= getDaysOfNoInfectionsMean(summary_df_replications) End_total_infection = summary_df_replications[summary_df_replications[&quot;infected&quot;]&lt;1] #End_total_infection[] #getDaysOfNoInfectionsMean(summary_df_replications) . Day that no more kids gets infected 23th day . #this plots the info in a stack fig = plt.figure(figsize=(12, 10)) ax = [fig.add_subplot(311, axisbelow=True), fig.add_subplot(312, axisbelow=True)] plt.xticks(np.arange(min(x), max(x)+1, 1.0)) max_infected_means=max(dataframe_means[&quot;mean_per_day_infected&quot;][0:days]) print(max_infected_means) ax[0].stackplot(dataframe_means[&quot;Day&quot;][0:days], dataframe_means[&quot;mean_per_day_infected&quot;][0:days], dataframe_means[&quot;mean_of_days_susceptible&quot;][0:days], dataframe_means[&quot;mean_of_days_removed&quot;][0:days], colors=pal, alpha=0.7) ax[0].set_title(f&#39;Expected Value of Susceptible, Infected,and Recoveredwith with {kids} kids, in {days} days, p={p}, replications= {replications}&#39;) ax[0].set_xlabel(&#39;Days&#39;) ax[0].set_ylabel(&#39;Expected Value per Status&#39;) ax[0].legend([ &#39;Infected&#39;, &#39;Susceptible&#39;, &#39;Recovered&#39;], loc=&#39;center&#39;) ax[0].set_xlim(1, days-2) ax[0].set_ylim(0, kids) #this plots a line with the max infected ax[0].annotate(&quot;Max infected(%.2f)&quot;%(max_infected_means), (0, max_infected_means),(0+3, max_infected_means+3), #(max_infected, max_infected), arrowprops=dict(arrowstyle=&#39;-&gt;&#39;)) ax[0].plot(np.array([0, days-1]), [max_infected_means, max_infected_means], lw=3, label=&#39;Max Infected Means&#39;) #this plots a line with the last day infected ax[0].annotate(&quot;End of Infections(%.2f)&quot;%(last_infected_mean), (last_infected_mean, 0),(last_infected_mean-6, 0+5), #(max_infected, max_infected), arrowprops=dict(arrowstyle=&#39;-&gt;&#39;)) ax[0].annotate(&quot;End of Infections(%.2f)&quot;%(last_infected_mean), (last_infected_mean, 0),(last_infected_mean-6, 0+5), #(max_infected, max_infected), arrowprops=dict(arrowstyle=&#39;-&gt;&#39;)) ax[0].plot(np.array([last_infected_mean,last_infected_mean]), [0, kids], lw=3, label=&#39;Last Infected Means&#39;) ############################################################################################# #This plot is for the infected on the sencond part ax[1].set_xlim(1, days-2) ax[1].set_ylim(0, max_infected_means*3) ax[1].stackplot(x, dataframe_means[&quot;mean_per_day_infected&quot;][0:days-1], dataframe_variance[&quot;Variance per day Infected&quot;][0:days-1], colors=pal, alpha=0.7) ax[1].legend([ &#39;Expected Value of Infected&#39;, &#39;Variance of Infected&#39;], loc=&#39;center&#39;) #this plots a vertical line of end of infection in plot 2 ax[1].annotate(&quot;End of Infections(%.2f)&quot;%(last_infected_mean), (last_infected_mean, 0),(last_infected_mean-6, 0+1), #(max_infected, max_infected), arrowprops=dict(arrowstyle=&#39;-&gt;&#39;)) ax[1].plot(np.array([last_infected_mean,last_infected_mean]), [0, kids], lw=3, label=&#39;Last Infected Means&#39;) #sets x title ax[1].set_xlabel(&#39;Days&#39;) ax[1].set_ylabel(&#39;Expected Value and Variance of Infected&#39;) . 2.84 . Text(0, 0.5, &#39;Expected Value and Variance of Infected&#39;) . from scipy import stats #[dataframe_means[&quot;mean_per_day_infected&quot;], #dataframe_variance[&quot;Variance per day Infected&quot;]] #testing how to run the chi squuare Xnot=chisquare([179, 208, 222, 199, 192]) #Cacluclates the Chi square passing 1- alph, degrees of freedom Xalpha = stats.chi2.ppf(q=0.95, df=4) print(Xnot,Xalpha) # for the project Xnot=chisquare(summary_df_replications[&quot;infected&quot;]) #Cacluclates the Chi square passing 1- alph, degrees of freedom k_observation=len(summary_df_replications[&quot;infected&quot;]) print(k_observation) Xalpha = stats.chi2.ppf(q=0.95, df=k_observation-1) print(Xnot,Xalpha) phat=.476 x=2 70*(1-phat)**(x-1)*phat (1-phat)**(x-1)*phat . NameError Traceback (most recent call last) &lt;ipython-input-13-c6ac1d942afc&gt; in &lt;module&gt; 5 6 #testing how to run the chi squuare -&gt; 7 Xnot=chisquare([179, 208, 222, 199, 192]) 8 #Cacluclates the Chi square passing 1- alph, degrees of freedom 9 Xalpha = stats.chi2.ppf(q=0.95, df=4) NameError: name &#39;chisquare&#39; is not defined . summary_last_recovered.head(5) . print(summary_last_recovered) results_replications_mean =pd.DataFrame(summary_last_recovered.mean()).T results_replications_mean_SIR= results_replications_mean.rename(columns={&quot;day&quot;: &quot;Day&quot;, &quot;infected&quot;:&quot;Total Expected Infected&quot;, &quot;susceptible&quot;:&quot;Total Expected Susceptible&quot;, &quot;recovered&quot;:&quot;Total Expected Removed&quot;, &quot;probability&quot;: &quot;Probability&quot;, &quot;count_prn&quot;: &quot;Cumulative PRNs&quot; } ) results_replications_mean_SIR[&quot;Total Expected Infected&quot;]=results_replications_mean_SIR[&quot;Total Expected Removed&quot;] results_replications_mean_SIR[&quot;Variance Infected&quot;]=0 #comparing the value if rounded display(round(results_replications_mean_SIR)) #not rounded display(results_replications_mean_SIR) display(summary_last_recovered.var()) . import statistics sample=summary_last_recovered[&quot;recovered&quot;] print(len(sample)) Zrbar= statistics.mean(sample) print(Zrbar) Sz_variance=statistics.variance(sample, xbar=Zrbar) print(Sz_variance) #1-stats.t.cdf(0.95,df=1) #enter the percentage to calculate the left side 90% equal to 10% in the regular table #np.sqrt(4) CILow=Zrbar - stats.t.ppf(0.975, df=len(sample)-1)*np.sqrt(Sz_variance/len(sample)) CIHigh =Zrbar + stats.t.ppf(0.975, df=len(sample)-1)*np.sqrt(Sz_variance/len(sample)) print(CILow,CIHigh) . summary_dataframe_means_Table= dataframe_means.rename(columns={&quot;day&quot;: &quot;Day&quot;,&quot;mean_per_day_infected&quot;:&quot;Expected Value of Infected &quot;, &quot;mean_of_days_susceptible&quot;:&quot;Excpected Value of Susceptibles&quot;, &quot;mean_of_days_removed&quot;:&quot;Expected Value of Removed&quot;} ) dataframe_means summary_dataframe_means_Table . summary_dataframe_means_Table_SIR=summary_dataframe_means_Table del summary_dataframe_means_Table_SIR[&quot;Day&quot;] summary_dataframe_means_Table.hist(figsize = (12,10)) #(summary_dataframe_means_Table[[&quot;Day&quot;, &quot;Expected Value of Infected&quot;]]).hist(column=&#39;Expected Value of Infected&#39;, bins=days,figsize=(8,4), grid=True,rwidth=0.9) . #Same as the mean olf how long the pandemic last print(f&#39;Day that no other kid gets infected = {summary_df_replications[&quot;infected&quot;].lt(1).argmax()}th day&#39;) #summary_df_replications[summary_df_replications[&quot;infected&quot;][:]&gt;0].iloc[0:20].mean() #summary_df_replications_greater_zero[&quot;infected&quot;][1].mean() #summary_df_replications.iloc[16:30] . # display(dataframe_means[dataframe_means[&quot;mean_per_day_infected&quot;][:]&gt;0]) # print (&quot;Table of Means of the Means For all Iteration&quot;) # display(dataframe_means[dataframe_means[&quot;mean_per_day_infected&quot;][:]&gt;0].mean()) . #Number of infected on day 0 for each replcation Infected_Day_1 = summary_df_replications[&quot;infected&quot;][0].iloc[0:1000] #print(Infected_Day_1) Infected_Day_1.hist( figsize=(10,4),grid=True).set_xlabel(&#39;Number of Infected on Day 1&#39;) Infected_Day_1.hist( ).set_ylabel(&#39;Frequency&#39;) . Ei=summary_df_replications[&quot;infected&quot;][0].mean() Oi=summary_df_replications[&quot;infected&quot;][0].iloc[0:1000].value_counts() print(f&#39;Ei = {Ei}&#39;) print(&#39;Observations&#39;) print(Oi) #this is incorrect Xnot=chisquare(summary_df_replications[&quot;infected&quot;][0]) #this is correct Xnot2=chisquare(Oi) #Cacluclates the Chi square passing 1- alph, degrees of freedom Xalpha = stats.chi2.ppf(q=0.95, df=len(Oi)-1-1) #print(Xnot, Xalpha) print(&#39;Xnot with stats package&#39;) print(Xnot2 ) print(&#39;X alpha&#39;) print(Xalpha) print(len(summary_df_replications[&quot;infected&quot;][0])) . Oi=summary_df_replications[&quot;infected&quot;][0].value_counts() #testing first 100 Xnot_list=[] Xbar_list=[] Xalpha_list=[] degrees=[] nlist=[] Geometric_per_replication=[] #30 days ends the replication window=60 for rep in range(1,int(990/window)-1): Oi=summary_df_replications[&quot;infected&quot;][0].iloc[(rep-1)*window:window*rep].value_counts() OiList=np.array(Oi) print(OiList) index=list(range(1,len(OiList)+1)) #[1,2,3,4,5] print(index) n=sum(OiList) print(OiList*index) sumXi=sum(OiList*index) #testing with out muliplying it for the index equal to X #sumXi=sum(OiList) Xbar=sumXi/n phat=1/Xbar print(f&#39;Phat = {phat} Xbar = {Xbar}&#39;) PGeometric=[] #phat=.476 for x in range(1,len(index)): PGeometric.append(((1-phat)**(x-1))*phat) PGeometric.append(1-sum(PGeometric)) PGeometric #n=70 nx=np.ones(len(index))*n print(nx) Ex= PGeometric*nx print(f&#39;Ex = {sum(Ex)}&#39;) #OiList=[34,18,2,9,7] Ex_OiList= Ex-OiList Xnot= sum(Ex_OiList**2/Ex) Xalpha = stats.chi2.ppf(q=0.95, df=len(Oi)-1-1) Xnot_list.append(Xnot) Xbar_list.append(Xbar) Xalpha_list.append(Xalpha) nlist.append(n) degrees.append(len(Oi)-1-1) Geometric_per_replication.append([PGeometric, Ex, Oi]) print(f&#39;Xnot = {Xnot}&#39;) #Xalpha() print(sum(PGeometric)) pd.DataFrame(data={&#39;P(X=x)&#39;:PGeometric, &#39;Ex&#39;:Ex, &#39;Ox&#39;:Oi}) Xalpha = stats.chi2.ppf(q=0.95, df=len(Oi)-1-1) print(f&#39;Xalpha = {Xalpha}&#39;) pd.DataFrame(data={&#39;P(X=x)&#39;:PGeometric, &#39;Ex&#39;:Ex, &#39;Ox&#39;:Oi}) . Geometric_per_replication . pd.DataFrame(Xnot_list).hist( ) pd.DataFrame(Xbar_list).hist( ) pd.DataFrame(Xbar_list).mean() #print(Xbar_list) #print(&#39;xxxx&#39;) #print(Xnot_list) Goodness = pd.DataFrame(data={&#39;Xnots&#39;:Xnot_list, &#39;Exs&#39;:Xbar_list, &#39;Xalphas&#39;:Xalpha_list, &#39;n&#39;:nlist, &#39;Degrees of Freedom&#39;:degrees}) Goodness[&quot;Xnot&lt;Xalpha&quot;]=Goodness[&#39;Xnots&#39;]&lt;Goodness[&#39;Xalphas&#39;] Goodness . Oi=summary_df_replications[&quot;infected&quot;][0].iloc[0:500].value_counts() #testing first 100 #Oi=summary_df_replications[&quot;infected&quot;][0].head(200).value_counts() OiList=np.array(Oi) print(OiList) index=list(range(1,len(OiList)+1)) #[1,2,3,4,5] print(index) n=sum(OiList) print(OiList*index) sumXi=sum(OiList*index) #testing with out muliplying it for the index equal to X #sumXi=sum(OiList) Xbar=sumXi/n phat=1/Xbar print(f&#39;Phat = {phat} Xbar = {Xbar}&#39;) PGeometric=[] #phat=.476 for x in range(1,len(index)): PGeometric.append(((1-phat)**(x-1))*phat) PGeometric.append(1-sum(PGeometric)) PGeometric #n=70 nx=np.ones(len(index))*n print(nx) Ex= PGeometric*nx print(f&#39;Ex = {Ex}&#39;) print(f&#39;Ox = {OiList}&#39;) #OiList=[34,18,2,9,7] Ex_OiList= Ex-OiList #print(Ex_OiList) print(f&#39;Ex - Ox = {Ex_OiList}&#39;) print(f&#39;[Ex - Ox]^2 = {Ex_OiList**2}&#39;) print(f&#39;[Ex - Ox]^2/Ex = {(Ex_OiList**2)/Ex}&#39;) print(f&#39; Sum [Ex - Ox]^2/Ex = {sum((Ex_OiList**2)/Ex)}&#39;) Xnot= sum(Ex_OiList**2/Ex) print(f&#39;Xnot = {Xnot}&#39;) #Xalpha() print(sum(PGeometric)) pd.DataFrame(data={&#39;P(X=x)&#39;:PGeometric, &#39;Ex&#39;:Ex, &#39;Ox&#39;:Oi}) Xalpha = stats.chi2.ppf(q=0.95, df=len(Oi)-1-1) print(f&#39;Xalpha = {Xalpha}&#39;) Table=pd.DataFrame(data={&#39;P(X=x)&#39;:PGeometric, &#39;Ex&#39;:Ex, &#39;Ox&#39;:Oi}) Table_add=Table.iloc[3]+Table.iloc[4] #adding tables so the last index includes 4 and 5 Adding_Tables=pd.concat([Table.head(3), pd.DataFrame(Table_add).T]) Ex_OiList=Adding_Tables[&quot;Ex&quot;]-Adding_Tables[&quot;Ox&quot;] print(Ex_OiList) Xnot= sum(Ex_OiList**2/Adding_Tables[&quot;Ex&quot;]) Xalpha = stats.chi2.ppf(q=0.95, df=len(Adding_Tables)-1-1) print(f&#39;Xnot = {Xnot}&#39;) print(f&#39;Xalpha = {Xalpha}&#39;) . sum(Ex)==sum(OiList) stats.chi2.ppf(q=0.95, df=2) len(Adding_Tables) . summary_df_replications[&quot;infected&quot;][0].iloc[30:60] . import numpy as np a=[] Xbar=Ei k=4 p=1/k #for exponential for i in range(1,k): a.append(round(Xbar*(-1*np.log(1-i/k) ),0)) print(a) #Infected_Day_1[&quot;groups&quot;]= Infected_Day_2=pd.DataFrame() Infected_Day_2[&quot;infected&quot;] = summary_df_replications[&quot;infected&quot;][0] print(Infected_Day_2.head()) Infected_Day_2[&quot;group&quot;]=pd.cut(summary_df_replications[&quot;infected&quot;][0],bins = a) Oi3=[Infected_Day_2[&quot;group&quot;].value_counts(),len(Infected_Day_2)-661-272] Oi3=[661,272,67] Oi3 Xnot3=chisquare(Oi3) Xnot3 . sample_infected = random.sample(list(Infected_Day_1), 200) k=3 Ei2=len(sample_infected)/k print(Ei2) Oi=pd.DataFrame(sample_infected) Oi=Oi[0].value_counts() print(Oi) Oi_lenEi=Oi-Ei2 print(Oi_lenEi**2/Ei2) sum(Oi_lenEi**2/Ei2) sum(Oi) . sum((Oi-len(Infected_Day_1)/k)**2/len(Infected_Day_1)/k) Ei2=len(Infected_Day_1)/k Oi_lenEi=Oi-Ei2 Oi_lenEi sum(Oi_lenEi**2/Ei2) . print( f&#39;Number of kids that are infected after {replications} replcations = {summary_df_replications[&quot;infected&quot;][0].mean()} on Day 1&#39;) . print( f&#39;Number of kids that are infected after {replications} replcations = {summary_df_replications[&quot;infected&quot;][1].mean()} on Day 2&#39;) . #Lenght_Uniform=len(summary_df_replications[&quot;infected&quot;][0]) X=summary_df_replications[&quot;infected&quot;][0] #Utest=np.random.uniform(0,1,Lenght_Uniform) #Exp_lambda=-1*(1/X)*np.log(Utest) print(f&#39;The mean number of students to get infected on the day 1 is :{X.mean(axis=0)}&#39;) . #summary_last_recovered[[&quot;susceptible&quot;,&quot;recovered&quot;]].hist(figsize = (10,5)) (summary_df_replications[[&quot;day&quot;, &quot;susceptible&quot;]]).hist(column=&#39;susceptible&#39;, bins=days,figsize=(8,4), grid=True,rwidth=0.9) (summary_df_replications[[&quot;day&quot;, &quot;infected&quot;]]).hist(column=&#39;infected&#39;, bins=days,figsize=(8,4), grid=True,rwidth=0.9) (summary_df_replications[[&quot;day&quot;, &quot;recovered&quot;]]).hist(column=&#39;recovered&#39;, bins=days,figsize=(8,4), grid=True,rwidth=0.9) . summary_last_recovered . summary_df_replications . #summary_df_replications.plot(&quot;day&quot;, y = [&quot;infected&quot;,&quot;susceptible&quot;, &quot;recovered&quot; ],figsize = (12,10)) #summary_df_replications.plot.hist(&quot;day&quot;, y = [&quot;infected&quot;,&quot;recovered&quot;,&quot;susceptible&quot; ],figsize = (12,10)) summary_df_replications[[&quot;infected&quot;,&quot;recovered&quot;,&quot;susceptible&quot;,&quot;probability&quot; ]].hist(figsize = (12,10)) . summary_last_recovered[[&quot;susceptible&quot;,&quot;recovered&quot;]].hist(figsize = (10,5)) . print(summary_df_replications.T) . summary_df_replications.hist(figsize = (16,18)) .",
            "url": "https://www.carlosaordonez.com/2022/01/04/Pandemic-simulation-covid.html",
            "relUrl": "/2022/01/04/Pandemic-simulation-covid.html",
            "date": " • Jan 4, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Pandemic Flu Spread Using Green Simulation Method For Small Sample Of Elementary Students",
            "content": "Pandemic Flu Spread Using “Green” Simulation Method for Small Sample of Elementary Students . Carlos Ordonez and Juan Carlos Pineda . Abstract: This paper studies a pandemic flu spread case applying a “green” simulation method, using pseudo-random numbers as presented in the paper by Wilson S., Alabdulkarim A. and Goldsman D. W, “Green Simulation of Pandemic Disease Propagation” (Wilson S., 2019) in a simulation environment build in Python. The scenario is an elementary school with twenty-one kids and the impact of infection when one infected kid enters the system. The findings and answers to the questions are presented in this paper. . Background and Description of the Problem | The novel Coronavirus pandemic has affected how the world operates, limiting our ability to mobilize and interact within each other. Throughout the history of humankind there have been several endemic and pandemic viruses that have attacked our society (Morens DM, 2009;200(7)), and researchers have study and implemented models to understand how the viruses spread among the population. For this paper the susceptible-infected-removed (SIR) model is used. The SIR model states that an individual at time t could change between three different states, susceptible (S), infected (I), and removed (R) (Morens DM, 2009;200(7)) (Munkhbat, 2019). . This paper analyzes the case of an elementary school with twenty-one students having one infected child on the first day. The infection rate ( beta) = 3 as the infected kid can infect on three consecutive days. The probability of infecting any other kid is p=0.02 and it is modeled using Bernoulli independent, identical distributed p trials. As a new kid becomes infected, he or she will have the same 3-day infection rate and the same p probability changes to infect other children. . For this simulation we will be using a simplified approached not considering any mitigation effect through social distance, or more complex models. The simplified approach is based on the “green” method presented in the paper by Wilson (Wilson S., 2019) that reuses many Bernoulli p trials between runs of susceptible individuals. The first section describes the setup of the environment. The second section describes the result with different iterations and answers to the questions such as the distribution of infection of Day1 , the expected number of kids infected on Day 1, the expected number of kids infected by Day 2 and a histogram detailing the length of the pandemic. . Main Findings . Modeling | | The SIR model is a mechanistic description of the spread of infectious disease. Each parameter is a state defined by differential equations that model the observed data at any given time t. The state susceptible refer to the individual that could be exposed to an infected person. Infected is the person that acquired the disease. Removal are individuals that either recovered or dead. . . Figure 1. SIR Model block diagram . The differential equations 1a,1b, 1c describes each of the models from the Figure 1. . ( frac{dS(t)}{ text{dt}} = - beta S(t)I(t)) ( frac{dI(t)}{ text{dt}} = beta S(t) I (t) - delta I(t)) , ( frac{ text{dR} left( t right)}{ text{dt}} = delta I left( t right) text{. }) (1) . 1) (b) (c) . Susceptible individuals will transition to the infected state at a rate of ( beta) and then will continue transition to the removed at a rate ( delta). This model is widely used in large populations. As presented by Wilson (Wilson S., 2019), the use of differential equation model tends to perform poorly in a setting with a small population. Also, he points out that additional short comings of this model do not take randomness into account and individual level behavior. . A better approach as Wilson et al. (Wilson S., 2019), proposed, is the use of discrete-event simulation, using a “green” simulation technique, where individuals enter in contact with each other and with the infected individual, and the outputs from the results of the previous days are being reused. This technique was introduced by Staum et. al (Feng &amp; Staum, 2015), and fits the model of the 21 elementary students in the project. Using a simplified version of the SIR model, we are simulating susceptible random individuals that may be infected by “Tommy”, the infected individual, at most once per day. Having a probability of infection p, each encounter being independent, therefore meeting the requirement of having encounters as Bernoulli trials. The simulation will end when no more susceptible individuals will get infected or no more susceptible individual will remain. The simulation runs for different sets of independent replications to calculate the expected number of kids infected, and to answer the questions presented in the project. . Setup of the Simulation Environment | The simulation starts by generating uniform - Unif (0,1) - pseudo-random numbers (PRN) U for each susceptible individual for each day per each replication. Twenty (20) PRNs are created for each susceptible kid on Day 1 and compared to the probability of infection p = 0.02. There is one super-infective kid, “Tommy”, which is represented as I(0)=1 arriving to the school on the first day. The number of susceptible at the beginning of Day 1 is represented by S(0)=20 and the number of removals R(0)=0. Tsai, et al. (Tsai, et al., 2010) proposed a way that all the k infectives entering the room, interacts with all n susceptible, by means of Bern(p) trials. Then, the probability of a susceptible becoming infected is equal to 1 - (q^{k}) with q = 1 – p. Therefore, performing n Bern(1 - (q^{k})). For example, on Day 1 the probability of p*(t=1) = 1-(1 - 0.02)1 = 0.02. It is important here to highlight, that as each day passes the probability changes depending on the number of k infected kids. The simulation will have a Bern(p*(t)) trials and will end when no more kids are infected. The number of k infected kids per day is calculated by comparing p*(t) &lt; U and updating the value of p* every day. On Day 2 PRNs are calculated for the remaining susceptible children and so on until no additional kid gets infected. To give another example, in order to calculate Day 2, assuming that result of the PRN for the end of the Day 1 is 2 infected, p = 0.02, the Day 2 will start with S(2) = 19, I(2)=2 including “Tommy”, p*(2)= 1 - ( 1 - 0.02)2 = 0.0396, R(0)= 0 and so on. The problem establishes that infected individuals will remain infected for a ( delta) of three days, therefore “Tommy” will change from “infected” to “removed” on Day 4, for our example R(4)=2. . Modeling and Results | Table 1 shows how the states from the SIR model changes, the probability and the number of cumulative PRNs generated from Day 1 until no additional children gets infected for the first replication. On Day 1 there is 1 infected, “Tommy” = I(1), with S(1) = 20 susceptibles, R(1) = 0 recovered, a probability p*(1)=0.02, with total number of PRNs generated, and a total number of PRNs= 20 (Cumulative PRNs) . Day 2 shows s one additional infected for a total of I(2) =2, S(2)= 19, R(2) = 0, the new p*(2)=0.0396, total cumulative PRNs= 40. On Day 4 we see the first removed, “Tommy”. As the days progress, we stop seeing new infections Day 6 and the last infected person gets removed on Day 10. Therefore the spread of infection ends on Day 10 with a total infected of I(10)=9 kids and S(10)=12 susceptible that did not get infected. . Table 1. Results for replication 1 with p=0.02 n=21, with I(0)=1 on the Day 1 . . Figure 2 shows the first replication using a stack plot where can be seen how the infection susceptible and removed individuals change status over time for the 21 kids with a 3 day infection rate, and a probability of infection of p=0.02. . The peak of the of the number of infected individuals happened on Day 5. On Day 6 started to die down until the spread stopped on Day 9 where the last kid was removed or recovered. The total of susceptible/not-infected individuals were 12, and the total of infected individuals were 9. . . Figure 2. Stack plot of 21 kids with 30 days for the first replication . Figure 3, shows the next step, running 100 replications of this same scenario and finding the expected value of the status per day to understand how the model behaves using the same base parameters. The top part shows the stacked plot of the expected value of each day for the different status. On the bottom part of the same figure is an expanded view of the rate of infections and the variance. The figure shows that on average the day with most infections is Day 3. Additionally, it shows that on average the infections end on Day 24. Table 4 on the Appendix section shows the value of each day for the different status (infected, susceptible, and removed) . . Figure 3. Top: Expected value of status per day with 21 kids in 30 days p=0.02 and 100 replications. Bottom : Expected value and variance of infected per day with 21 kids in 30 days p=0.02 and 100 replications . Taking the expected value for each of the three status after 100 replications, in average 7.13% of students get infected, 13.87% of students remain susceptible, and 7.13% gets removed. Table 2 presents the restuls. We can imply that about 7 kids get infected and 14 kids do not. The variance as seen in orange on the bottom graph of Figure 3, has it highest pick on Day 6 with a pick of 5.15 and expected value of 1.77 , implying that number of kids infected for that Day 6 could change between 2 to 5. This could be the result of having a three (3) day infection rate. . Table 2. Expected value per status after 100 replications . . The following histograms on Figure 4 shows where most of values fall after the 100 replications. It can be seen that at least one person gets infected most of the time, which is obvious since the system is initialize with Tommy, the infected kid. After that, it varies between two to six following what looks like a geometric distribution considering that we are doing the number of Bernoulli trials until the first success. The recovered distribution seems to follow also a geometric distribution and the susceptible values complement recovered ones. . . Figure 4. Histograms of infected, recovered/removed, susceptible and the probability after 100 replications . To validate that the values for Day 1 corresponded to a geometrically distribution, we performed a goodness of fit with a group of smaller values of n=60 for replications 1 to 990 in batches, with a total number of batches equals to 14 batches. We encountered that 11 times out of 14 our ( chi_{o}) was smaller than the ( chi_{ alpha}) at 0.95. Resulting that it is very likely that the distribution for the first day fits the geometric. Results of the 14th batch is shown below. Table 5 in the Appendix shows the total results per batch. . . Figure 5. 14th Batch results for Goodness of fit. . Answer to the questions presented in the Project . What is the distribution of the number of kids that Tommy infects on Day 1? | | After taking the values of m=100 replications and plotting the results, we realized there are at least one kit kid gets infected 69% of the time. Similarly, at least 2 kids get infected 21% of the time and at least 3 kids get infected 10% of the time for the 100 replications reflected on Table 2. . So, we have H0: (X_{1}, X_{2}, X_{3}, …, X_{n} sim Geom( frac{1}{ lambda} )) . Table 3 Infected kids on day 1 for n=100 replications . . Therefore, the distribution for Day 1 as presented in the histogram of Figure 3 shows a geometric distribution. . . Figure 6. Distribution for Day 1 . What is the expected number of kids that Tommy infects on Day 1? | The expected number of kids that Tommy infects on Day 1 can be defined: . (Ε lbrack D = 1 rbrack = sum_{i = 1}^{k} frac{k}{n}). . The result is equal to 1.48. . What is the expected number of kids that are infected by Day 2 (you can count Tommy if you want)? | Similarly, the expected number of kids that are infected on Day 2 is equal to 2.07 . ( Ε lbrack D = 2 rbrack = sum_{i = 1}^{k} frac{k}{n}). . Simulate the number of kids that are infected on Days 1,2,. . . . Do this many times. What are the (estimated) expected numbers of kids that are infected by Day i, i = 1, 2, . . .? Produce a histogram detailing how long the “epidemic” will last. | . Figure 7. Histogram of expected value per status . After running the simulation for 100 times (m=100) and taking the expected value for each status per day, we see that the infected values approximate to a geometric distribution. As can be seen in the histograms below on Figure 6. The Expected Value of Susceptible and Expected Value of Infected kids are likely to follow a geometric distribution. The Expected value of the removed roughly fits a skewed normal distribution, which is an encouraging result as is similar to the one presented by Disworh (Disworth, 2019). . The values of the Expected Value of removed kids and the Expected value of the infected can be seen as a “mirror” because as the days progress, the kids that get infected become removed. . Conclusions | After reading all the material on Pandemic and/or Disease transmission we learned the way how these problems are modeled. SEIR and SIR models are used to capture the process of the infection. The SEIR model is more general, however for our solution we picked the SIR model as described by Wilson et al (Wilson S., 2019) due to its simplicity way of modeling by means of Bernoulli process. . One key takeaway of the simulation is that even though the model is simple, implementing it has to be done carefully since generating PRN’s in a large number of replications can be costly from the computing stand point. This Is very important and we noticed it after growing our replication number from 10, to 100 to 1,000 and then further from that. . Once we determined the right length of the spread of the virus, the “green” simulation technique used for this project becomes computationally efficient. The “green” simulation technique considers a probability that reuses many Bernoulli p trials between runs of susceptible individuals, updating the rate of infected induvial between consecutive days. The results showed that in average the pandemic lasted k= 24 days after m= 100 replications, with n= 20 susceptible kids exposed to 1 infected on Day 1. It also resulted that the total number of expected kids I(t) = 7 infected a including Tommy; and the total S(t) =14 susceptible kids, after some rounding. The distribution of the infected individuals after the m=100 replication for Day 1 is likely to be geometric. The same is the case for the distribution of the expected values of infected kids. The variance peaked on Day 6, which could be due to the three days that infected kids continue spreading the virus. . Finally, this simulation shows a simplified way to get acquainted with using PRNs to estimate the rate of infections. Further work could include factoring the use of social distance or other means that could help mitigate the infection rate. . References . Disworth, M. (2019, January 2). Infecting Modeling - Part 1. (Towards Data Science) Retrieved from https://towardsdatascience.com/infection-modeling-part-1-87e74645568aFeng, M., &amp; Staum, J. (2015). Green simulation designs for repeated experiments. In Proceedings of the 2015 Winter.Morens DM, F. G. ( 2009;200(7)). What is a pandemic? . J Infect Dis., 1018-1021.Munkhbat, B. (2019). A Computational Simulation Model for Predicting Infectious Disease Spread using the Evolving Contact Network Algorithm. Master Thesis.Tsai, M., Chern, T., Chuang, J., Hsueh, C., Kuo, H., Liau, C., . . . Shen, C. (2010). Efficient simulation of the spatial transmission dynamics of influenza. PLoS ONE, 5, e13292.Wilson S., A. A. ( 2019). Simulation of Pandemic Disease Propagation . Symmetry, 11(4), 580. . Appendix . Table 4. Expected value per day of Status of Infected, Susceptible and Remove for p =0.02, with 21 kids and 100 replications . . Table 5.Results per batch per replications of Goodness of fit for Day 1 . .",
            "url": "https://www.carlosaordonez.com/2020/11/27/Pandemic-Flu-Spread-Using-Green-Simulation-Method-for-Small-Sample-of-Elementary-Students.html",
            "relUrl": "/2020/11/27/Pandemic-Flu-Spread-Using-Green-Simulation-Method-for-Small-Sample-of-Elementary-Students.html",
            "date": " • Nov 27, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Calculating The Cost Of Overbooking Airline Tickets Using Analytics",
            "content": "This article was originally posted on Linkedin here prior to the pandemic Using Python to calculate the cost of overbooking an airline ticket. . The code can be found in GitHub here. . I have been curious to use data analytics in aviation operations. I found that one of the models that airlines use is the binomial function to determine what is the optimum revenue the airline, after calculating the probability of the number of passengers that will show up when overbooking a specific route. The probability is modeled with binomial function assuming that each show or no show sample is independent of each other. This probability is affected by many possible factors like delayed flights, traffic jams, canceling a flight due to personal reasons, etc. . Binomial function This article was inspired by Cory Simon ’s article on “ By How Many Flights an Airline Should Overbook”. In his analysis, he uses a normal approximation of a binomial distribution. He allocates fixed parameters such as a number of seats per aircraft, the probability of a passenger and expands to a range of additional tickets beyond capacity sold the price per ticket and the price of the voucher. The voucher in his example is defined as the cost the airline incurs to pay passengers for an overbooked ticket. . I decided to expand a little more and create a function that could allow passing the value of the ticket, the voucher cost, the number of seats, the probability rate of a passenger showing up and the number of additional seats. I used Python’s numpy cumulative distributive function to calculate the probability of passengers to show to a flight beyond capacity (Total Seats Available in the aircraft + total additional overbooking tickets). The function also calculates the max number of possible seats available that could be overbooked. This is defined by p * x=Total Seats Available. If the probability is equal to 1 then all seats will be taken. By solving x, then x=Total Seats Available/p _will give the maximum seats available for that probability _p. A good explanation of the calculation of the probability of overbooking can also be found here. . Let’s assume the case of  Embraer 175  flying  Miami to Cleveland with 128 seats  in the main cabin. . Embraer-175-cabin-Layout For this calculation, I am focused on the number of additional tickets beyond capacity. The following example tests a ticket with a value of $512.00 from Miami to Cleveland in American Airlines, assuming a probability rate of passengers to show at this time on this date at 90%. The maximum number of additional seats the airline could sell is equal to_ Max_Seats = 128 /.9 = 142.22 - 128 = 14.22 _rounded down will give  14  additional seats on  128  seat aircraft, with a probability of  90 % of the passengers showing up and a voucher cost for overbooking of  $200.00. . Air Fare example for Binomial Function The airline by selling additional tickets increases its revenue, but the net profit decreases if they end up paying for too many vouchers. The voucher cost could include the cost of re-scheduling passengers. In this example, it is omitted. I am trying to find the optimum amount of additional tickets the airline could sell. . Overbooking Calculation image The result of this graph shows the maximum profit per additional ticket at a fixed voucher cost, with the maximum amount of overbooking tickets (14). The maximum total profit can be reached at $66,995.94 overbooking 6 tickets of the 14. . Expected Reveneu vs tickets beyond capacity graph Table with Expected profit by exceeding overbooking The following table test different vouchers values based on the suggested overbooking tickets found on the previous table. . Table with Overbooking tickets sold and max profit The table shows that the ideal  Voucher_Cost  should be less than $200.00, overbooking 6 seats. If the voucher cost offered is higher than $600.00 the airline should not overbook any additional tickets. . This analysis is just the first to understand a model, in this case, the binomial function, when applying analytics in aviation operations. It is important to highlight that there are 4 moving variables: Ticket sale price, the voucher cost, probability of passengers to show at a specific time and date, and the number of seats per aircraft. .",
            "url": "https://www.carlosaordonez.com/2020/08/15/calculating-the-cost-of-overbooking-airline/",
            "relUrl": "/2020/08/15/calculating-the-cost-of-overbooking-airline/",
            "date": " • Aug 15, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://www.carlosaordonez.com/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://www.carlosaordonez.com/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am an electrical engineer, data scientist, business focused, helping companies adopt a digital mindset. . To learn more about me, check my LinkedIn. .",
          "url": "https://www.carlosaordonez.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://www.carlosaordonez.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}